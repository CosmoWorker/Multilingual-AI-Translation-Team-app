![github-submission-banner](https://github.com/user-attachments/assets/a1493b84-e4e2-456e-a791-ce35ee2bcf2f)

# 🚀 Multimodal Language Utility Hub

> Transforming how you communicate with our powerful AI-driven tools for text-to-speech, speech-to-text, translation, and image description and much more.

---

## 📌 Problem Statement
### Problem Statement 1 - Weave AI magic with Groq

---

## 🎯 Objective

What problem does your project solve, and who does it serve?  
My project solves the problem of limited translation methods that often lack accuracy and context. Traditional translation tools typically focus only on text or speech, and their responses can sometimes be imprecise. My web-app offers a more versatile and context-aware approach by supporting multiple languages and translation modes, including speech-to-text and text-to-speech and more. This allows users to easily understand content, like memes, in their local language and translate it into their native speech almost instantly. It’s especially useful for people seeking quick, accurate, and seamless communication across language barriers.

---

## 🧠 Team & Approach

### Team Member:  
- V Tarang (Student dev)

### Your Approach:  
- I chose this problem because it brings together various translation tools and gives me an opportunity to explore how to leverage multiple state-of-the-art models for direct translations. It also opens up possibilities to extend the project further into a full utility hub for translations across different mediums like text, speech, and images.
- One of the main challenges was finding a reliable model that could handle direct translations, as many APIs didn’t offer a simple, unified solution. Handling audio — parsing it correctly, formatting it properly for the model, and displaying the results — was particularly tricky. Similarly, sending and processing image files was a challenge, both due to API limitations and the need to format them properly for display and model input.
- I made some pivots, including switching between different models to improve translation quality by using them simultaneously when needed. Another breakthrough was figuring out that sending audio as blobs or chunks helped the backend process it more efficiently. I also spent time brainstorming the UX — how it should look and feel — and thinking about ways to provide richer, more helpful descriptions for translated images.

---

## 🛠️ Tech Stack

### Core Technologies Used:
- Frontend: Nextjs
- Backend: Nextjs
- Database: n/a
- APIs: groq
- Hosting: Vercel

### Sponsor Technologies Used (if any):
- [✅] **Groq:** _How you used Groq_  
- [ ] **Monad:** _Your blockchain implementation_  
- [ ] **Fluvio:** _Real-time data handling_  
- [ ] **Base:** _AgentKit / OnchainKit / Smart Wallet usage_  
- [ ] **Screenpipe:** _Screen-based analytics or workflows_  
- [ ] **Stellar:** _Payments, identity, or token usage_
---

## ✨ Key Features

Highlight the most important features of your project:

- ✅ State of the art models with incredibly fast inference & compute speed with exceptional accuracy.
- ✅ Seamlessly convert between different communication formats in one platform.
- ✅ Convert any text into natural-sounding speech with multiple voices and languages.
- ✅ Extract text from images or get detailed descriptions with translations of image content.

Add images, GIFs, or screenshots if helpful!

---

## 📽️ Demo & Deliverables

- **Demo Video Link:** https://www.loom.com/share/9c187edad4ad4406b546a6ceee313bca?sid=a0400c92-c45c-4642-a07c-ea6d8d7a81a3 

---

## ✅ Tasks & Bonus Checklist

- [✅] **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form** (Details in Participant Manual)  
- [ ] **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)**  (Details in Participant Manual)
- [✅] **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**  (Details in Participant Manual)

*(Mark with ✅ if completed)*

---

## 🧪 How to Run the Project

### Requirements:
- Node.js - ^v20
- pnpm, npm
- API Keys - Groq API, Clerk Secret Key
- .env file setup - .env.example (for reference)

### Local Setup:
```bash
# Clone the repo
git clone https://github.com/CosmoWorker/project-name

# Install dependencies
cd project-name
pnpm install

# Start development server
pnpm dev

# Test Credentials
username - lakakaisdope@gmail.com
password - 321Test*

## 🧬 Future Scope

List improvements, extensions, or follow-up features:

- 📈 More integrations - Future plans include building a team chat app and a one-on-one video chat platform with seamless translation integration and contextual analysis(if any). We also plan to store essential required user data in a database.
- 🛡️ Security enhancements - Focused on strengthening privacy and ensuring that all stored data remains protected against leaks and unauthorized access.
- 🌐 Localization / broader accessibility - Expanding to native mobile applications to make the platform even more accessible to a wider, diverse & global audience.

---

## 📎 Resources / Credits

- APIs or datasets used  -  Groq
- Open source libraries or tools referenced  - Shadcn 
- Acknowledgements  - bolt(stackblitz), Clerk docs

---

## 🏁 Final Words

It was a nice opportunity for me to work on a project from a pool of problem statements provided by the incredible community of HackHazards. This was also a learning opportunity all along while building something new which builds up the necessary skills towards building even more such projects in this journey of shipping code.

---
